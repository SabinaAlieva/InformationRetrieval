{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import collections\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import pymorphy2\n",
    "\n",
    "\n",
    "stop_words = stopwords.words('russian')\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(r\"^\\s+|\\n|\\r|\\t|\\s+$\", \"\", text) # отступы\n",
    "    text = re.sub(r'.[0-9]+', ' ', text) # цифры\n",
    "    text = re.sub(r'.[a-z]+', ' ', text) # английские символы\n",
    "    text = re.sub(r'[^\\w\\s]',' ', text) # пунктуация\n",
    "    text = text.lower() # регистр\n",
    "    text = \" \".join([word for word in text.split(\" \") if (word not in stop_words)]) # стоп-слова\n",
    "    text = \" \".join([t for t in text.split(\" \") if len(t) > 0]) # лишние пробелы\n",
    "    text = \" \".join([morph.parse(word)[0].normal_form for word in text.split(\" \")]) # лемматизация\n",
    "    return str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_source = \"datapikabu_dataset_new.csv\"\n",
    "filename = \"pikabu_dataset_longText.csv\"\n",
    "filename_new = \"pikabu_dataset_clear.csv\"\n",
    "\n",
    "hot = \"hot_dataset.csv\"\n",
    "hot_new = \"hot_dataset_processed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename_source)\n",
    "df_enough = df[df['Text'].map(lambda x: len(str(x)) > 1000)]\n",
    "df_enough.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(filename)\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, TimestampType, StringType\n",
    "\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"PYSPARK_PYTHON\"] = \"python3\"\n",
    "sc = SparkContext(master='local[*]')\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PySpark\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "df_spark = spark.read.csv(filename, inferSchema=True, header=True).toDF('Number', 'FileName', 'Title', 'Link', 'ArticleId', 'Date', 'Views',\n",
    "       'Author', 'Tags', 'AmountComments', 'Rating', 'Text')\n",
    "\n",
    "prepr = F.udf(preprocessing, StringType())\n",
    "\n",
    "df_clear = df_spark.withColumn('Text', prepr(df_spark['Text'])) \\\n",
    "    .withColumn('Tags', prepr(df_spark['Tags'])) \\\n",
    "    .withColumn('Title', prepr(df_spark['Title'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clear = df_clear.toPandas()\n",
    "df_clear.to_csv(filename_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(hot)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Number', 'FileName', 'Title', 'Link', 'ArticleId',\n",
       "       'Date', 'Views', 'Author', 'Tags', 'AmountComments', 'Rating', 'Text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filename_new)\n",
    "filename = \"pikabu_dataset_good.csv\"\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Title', 'Link', 'Date', 'Views', 'Author', 'Tags', 'AmountComments', 'Rating', 'Text']]\n",
    "df.to_csv(filename, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>Date</th>\n",
       "      <th>Views</th>\n",
       "      <th>Author</th>\n",
       "      <th>Tags</th>\n",
       "      <th>AmountComments</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>человек</td>\n",
       "      <td>https://pikabu.ru/story/o_lyudyakh_2801350</td>\n",
       "      <td>2014-11-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LisSiN</td>\n",
       "      <td>игра демиург текст</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>демиург мазукт прийти гость свой друг демиург ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>один история кафе добавка</td>\n",
       "      <td>https://pikabu.ru/story/eshche_odna_moya_istor...</td>\n",
       "      <td>2014-11-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bambaleilo</td>\n",
       "      <td>работа случай жизнь неприятный ситуация помощь...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>писать работать кассир кафе время летний каник...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>сначала добиться</td>\n",
       "      <td>https://pikabu.ru/story/snachala_dobeysya_2801509</td>\n",
       "      <td>2014-11-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kakashkolub</td>\n",
       "      <td>сперва добиться паста притча идиотизм текст</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>однажды встать кровать пойти завтракать стол с...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>счастие это просто</td>\n",
       "      <td>https://pikabu.ru/story/schaste__yeto_prosto_2...</td>\n",
       "      <td>2014-11-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pryasha</td>\n",
       "      <td>мой стих текст лирика</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>гдеть наверное дуть бризктоть резать крупно за...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>крым наш</td>\n",
       "      <td>https://pikabu.ru/story/kryim_nash_2801415</td>\n",
       "      <td>2014-11-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kaprichio</td>\n",
       "      <td>украина россия мой крым текст</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-145.0</td>\n",
       "      <td>момент передача крым украина крым восемь магаз...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Title  \\\n",
       "0                    человек   \n",
       "1  один история кафе добавка   \n",
       "2           сначала добиться   \n",
       "3         счастие это просто   \n",
       "4                   крым наш   \n",
       "\n",
       "                                                Link        Date  Views  \\\n",
       "0         https://pikabu.ru/story/o_lyudyakh_2801350  2014-11-05    NaN   \n",
       "1  https://pikabu.ru/story/eshche_odna_moya_istor...  2014-11-05    NaN   \n",
       "2  https://pikabu.ru/story/snachala_dobeysya_2801509  2014-11-05    NaN   \n",
       "3  https://pikabu.ru/story/schaste__yeto_prosto_2...  2014-11-05    NaN   \n",
       "4         https://pikabu.ru/story/kryim_nash_2801415  2014-11-05    NaN   \n",
       "\n",
       "        Author                                               Tags  \\\n",
       "0       LisSiN                                 игра демиург текст   \n",
       "1   bambaleilo  работа случай жизнь неприятный ситуация помощь...   \n",
       "2  Kakashkolub        сперва добиться паста притча идиотизм текст   \n",
       "3      pryasha                              мой стих текст лирика   \n",
       "4    kaprichio                      украина россия мой крым текст   \n",
       "\n",
       "   AmountComments  Rating                                               Text  \n",
       "0             1.0     8.0  демиург мазукт прийти гость свой друг демиург ...  \n",
       "1            11.0    11.0  писать работать кассир кафе время летний каник...  \n",
       "2             8.0   -13.0  однажды встать кровать пойти завтракать стол с...  \n",
       "3             8.0     9.0  гдеть наверное дуть бризктоть резать крупно за...  \n",
       "4            60.0  -145.0  момент передача крым украина крым восемь магаз...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(filename)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Прочее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.withColumn('Text', reduce(preprocessing, col('Text'))) \\\n",
    ".withColumn('Title', F.map(preprocessing, col('Title'))) \\\n",
    ".withColumn('Tags', F.map(preprocessing, col('Tags'))) \\\n",
    ".toPandas().to_csv(hot_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(master='local[*]')\n",
    "sqlContext = SQLContext(sc)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"PySpark\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "df_spark = spark.read.csv(hot, inferSchema=True, header=True).toDF('Number', 'FileName', 'Title', 'Link', 'ArticleId', 'Date', 'Views',\n",
    "       'Author', 'Tags', 'AmountComments', 'Rating', 'Text')\n",
    "\n",
    "def rowwise_function(row):\n",
    "    row_dict = row.asDict()\n",
    "    row_dict['Text'] = preprocessing(row_dict['Text'])\n",
    "    row_dict['Tags'] = preprocessing(row_dict['Tags'])\n",
    "    row_dict['Title'] = preprocessing(row_dict['Title'])\n",
    "    newrow = Row(**row_dict)\n",
    "    return newrow\n",
    "\n",
    "ratings_rdd = df_spark.rdd\n",
    "ratings_rdd_new = ratings_rdd.map(lambda row: rowwise_function(row))\n",
    "ratings_new_df = sqlContext.createDataFrame(ratings_rdd_new)\n",
    "#ratings_new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_new_df.toPandas().to_csv(hot_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSchema = StructType([\n",
    "    StructField('Number',IntegerType(), True),\n",
    "    StructField('FileName', StringType(), True), \n",
    "    StructField('Title', StringType(),True), \n",
    "    StructField('Link', StringType(), True),\n",
    "    StructField('ArticleId', IntegerType(), True), \n",
    "    StructField('Date', StringType(), True), \n",
    "    StructField('Views', IntegerType(), True),\n",
    "    StructField('Author', StringType(), True), \n",
    "    StructField('Tags', StringType(), True), \n",
    "    StructField('AmountComments', IntegerType(), True), \n",
    "    StructField('Rating', IntegerType(), True), \n",
    "    StructField('Text', StringType(), True)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.read.csv(filename, inferSchema=True, header=True).toDF('Number','FileName', 'Title', 'Link', 'ArticleId', 'Date', 'Views',\n",
    "       'Author', 'Tags', 'AmountComments', 'Rating', 'Text')\n",
    "\n",
    "def rowwise_function(row):\n",
    "    row_dict = row.asDict()\n",
    "    row_dict['Text'] = preprocessing(row_dict['Text'])\n",
    "    row_dict['Tags'] = preprocessing(row_dict['Tags'])\n",
    "    row_dict['Title'] = preprocessing(row_dict['Title'])\n",
    "    newrow = Row(**row_dict)\n",
    "    return newrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_rdd = df_spark.rdd\n",
    "ratings_rdd_new = ratings_rdd.map(lambda row: rowwise_function(row))\n",
    "ratings_new_df = sqlContext.createDataFrame(ratings_rdd_new, dfSchema)\n",
    "#ratings_new_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toCSVLine(data):\n",
    "    return ','.join(str(d) for d in data)\n",
    "\n",
    "lines = ratings_rdd_new.map(toCSVLine)\n",
    "lines.saveAsTextFile(filename_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_new_df.write.format('com.databricks.spark.csv').save(filename_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_new_df.write.csv(filename_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
